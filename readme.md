# **ðŸ•·ï¸ Froxy**

> A chill, open-source web engine that crawls, indexes, and vibes with web content using semantic search.

![froxy banner](https://github.com/MultiX0/froxy/blob/main/banner.png?raw=true)

---

## ðŸ’¡ What is Froxy?

Froxy is a modular full-stack web engine designed to crawl web pages, extract content, and index it using **semantic embeddings** for intelligent search â€” all powered by modern tools. It includes:

* A **Go**-based crawler (aka the spider ðŸ•·ï¸) with real-time indexing
* **FastEmbed** service for generating semantic embeddings
* **Qdrant** vector database for semantic search
* **Froxy Apex** - AI-powered intelligent search (Perplexity-style)
* A **PostgreSQL** database for structured data
* A **Next.js** front-end UI (fully integrated with real APIs)

This project is built for learning, experimenting, and extending â€” great for developers who want to understand how modern semantic search engines work from scratch.

> Fun fact: I made this project in just **3 days** â€” so it might not be perfect, but you know what?
> **It works!**
>
> *(We'll keep evolving this codebase together â¤ï¸)*

> Note: I prefer simplicity over unnecessary complexity. We might make the architecture more advanced in the future, but for now, it's simple, clean, and straightforwardâ€”no fancy stuff, no over-engineering. It's just a chill project for now. If needed, we can scale and make it more complex later. After all, it started as a fun projectâ€”nothing more. <3

---

## ðŸ” Features

* ðŸŒ Crawl websites with real-time indexing (Go)
* ðŸ§  Semantic search using embeddings (FastEmbed + Qdrant)
* ðŸ¤– AI-powered intelligent search with LLM integration (Froxy Apex)
* ðŸš€ Vector similarity search for intelligent results
* ðŸ“Š Chunk-based relevance scoring with cosine similarity
* ðŸ•º Store structured data in PostgreSQL
* ðŸŽ¨ Modern UI in Next.js + Tailwind
* ðŸ³ Fully containerized with Docker

> The frontend is fully connected to the backend and provides semantic search capabilities.

---

## ðŸ“‚ Folder Structure

```
froxy/
â”œâ”€â”€ front-end/          # Next.js frontend
â”‚   â”œâ”€â”€ app/            # App routes (search, terms, about, etc.)
â”‚   â”œâ”€â”€ components/     # UI components (shadcn-style)
â”‚   â”œâ”€â”€ hooks/          # React hooks
â”‚   â”œâ”€â”€ lib/            # Utility logic
â”‚   â”œâ”€â”€ public/         # Static assets
â”‚   â””â”€â”€ styles/         # TailwindCSS setup
â”œâ”€â”€ indexer-search/     # Node.js search backend
â”‚   â””â”€â”€ lib/
â”‚       â”œâ”€â”€ functions/ 
â”‚       â”œâ”€â”€ services/   # DB + search service
â”‚       â””â”€â”€ utils/      # Helper utilities
â”œâ”€â”€ froxy-apex/         # AI-powered intelligent search service
â”‚   â”œâ”€â”€ api/            # API endpoints
â”‚   â”œâ”€â”€ db/             # Database connections
â”‚   â”œâ”€â”€ functions/      # AI processing logic
â”‚   â”œâ”€â”€ llama/          # LLM integration
â”‚   â”œâ”€â”€ models/         # Data models
â”‚   â””â”€â”€ utils/          # Helper utilities
â”œâ”€â”€ spider/             # Web crawler in Go with real-time indexing
â”‚   â”œâ”€â”€ db/             # DB handling (PostgreSQL + Qdrant)
â”‚   â”œâ”€â”€ functions/      # Crawl + indexing logic + Proxies (if-need it)
â”‚   â”œâ”€â”€ models/         # Data models
â”‚   â””â”€â”€ utils/          # Misc helpers
â”œâ”€â”€ fastembed/          # FastEmbed embedding service
â”‚   â”œâ”€â”€ models/         # Cached embedding models
â”‚   â””â”€â”€ docker-compose.yml
â”œâ”€â”€ qdrant/             # Qdrant vector database
â”‚   â””â”€â”€ docker-compose.yml
â”œâ”€â”€ db/                 # PostgreSQL database
â”‚   â”œâ”€â”€ scripts/        # Shell backups
â”‚   â””â”€â”€ docker-compose.yml
â”œâ”€â”€ froxy.sh            # Automated setup & runner script
â”œâ”€â”€ LICENSE             # MIT License
â””â”€â”€ readme.md           # This file
```

---

## âš™ï¸ Getting Started

### Requirements

* Node.js (18+)
* pnpm or npm
* Go (1.23+)
* Docker & Docker Compose
* At least 2GB RAM (for embedding service)

### Quick Setup (Recommended for Crawler)

For the fastest crawler setup without dealing with configuration details:

```bash
# Make the script executable and run it
chmod +x froxy.sh
./froxy.sh
```

The script will automatically:
- Set up all environment variables with default values
- Create the Docker network
- Start all required services (PostgreSQL, Qdrant, FastEmbed)
- Health check all containers
- Guide you through the crawling process

**Note**: The `froxy.sh` script only handles the crawler setup. You'll need to manually start the `froxy-apex` AI service and `front-end` after crawling.

### Manual Setup

If you prefer to set things up manually:

```bash
# 1. Create Docker network
docker network create froxy-network

# 2. Start Qdrant vector database
cd qdrant
docker-compose up -d --build

# 3. Start PostgreSQL database
cd ../db
# Set proper permissions for PostgreSQL data directory
sudo chown -R 999:999 postgres_data/
docker-compose up -d --build

# 4. Start FastEmbed service
cd ../fastembed
docker-compose up -d --build

# 5. Wait for all services to be healthy, then run the crawler
cd ../spider
go run main.go

# 6. After crawling, start the search backend
cd ../indexer-search
npm install
npm start

# 7. Start the AI-powered search service (Froxy Apex)
# Make sure to configure froxy-apex/.env first
cd ../froxy-apex
go run main.go

# 8. Launch the front-end
cd ../front-end
npm i --legacy-peer-deps
npm run dev
```

---

## ðŸ” Environment Variables

### Default Configuration

All services use these environment variables (automatically set by `froxy.sh`):

```env
# Database Configuration (for spider & indexer-search)
DB_HOST=localhost
DB_PORT=5432
DB_USER=froxy_user
DB_PASSWORD=froxy_password
DB_NAME=froxy_db
DB_SSLMODE=disable

# Vector Database Configuration
QDRANT_API_KEY=froxy-secret-key
QDRANT_HOST=http://localhost:6333

# FastEmbed Service
EMBEDDING_HOST=http://localhost:5050

# AI Service (for froxy-apex)
LLM_API_KEY=your_groq_api_key
API_KEY=your_froxy_apex_api_key
```

### Service-Specific Variables

#### `db/.env`
```env
POSTGRES_DB=froxy_db
POSTGRES_USER=froxy_user
POSTGRES_PASSWORD=froxy_password
DB_NAME=froxy_db
DB_SSLMODE=disable
```

#### `qdrant/.env`
```env
QDRANT_API_KEY=froxy-secret-key
```

#### `spider/.env` & `indexer-search/.env`
```env
DB_HOST=localhost
DB_PORT=5432
DB_USER=froxy_user
DB_PASSWORD=froxy_password
DB_NAME=froxy_db
DB_SSLMODE=disable
QDRANT_API_KEY=froxy-secret-key
EMBEDDING_HOST=http://localhost:5050
```

#### `froxy-apex/.env`
```env
LLM_API_KEY=your_groq_api_key
QDRANT_HOST=http://localhost:6333
EMBEDDING_HOST=http://localhost:5050
API_KEY=your_froxy_apex_api_key
QDRANT_API_KEY=froxy-secret-key
```

#### `front-end/.env`
```env
API_URL=http://localhost:8080
API_KEY=your_api_key
WEBSOCKET_URL=ws://localhost:8080/ws/search
FROXY_APEX_API_KEY=your_froxy_apex_api_key
ACCESS_CODE=auth_access_for_froxy_apex_ui
AUTH_SECRET_TOKEN=jwt_token_for_apex_ui_to_calc_the_usage
```

> ðŸ’¡ The `froxy.sh` script automatically creates `.env` files with working default values for the crawler and database services. You'll need to manually configure `froxy-apex/.env` and `front-end/.env` for the AI search and UI components.

---

## ðŸ¤” How it works

### Traditional Search
1. **Crawler** pulls website content from your provided URLs
2. **Real-time indexing** generates semantic embeddings using FastEmbed
3. **Qdrant** stores vector embeddings for semantic similarity search
4. **PostgreSQL** stores structured metadata
5. **Frontend** provides intelligent semantic search interface

### AI-Powered Search (Froxy Apex)
1. **User query** is received and processed
2. **Query enhancement** using Llama 3.1 8B via Groq API
3. **Embedding generation** for the enhanced query using FastEmbed
4. **Vector search** in Qdrant to find relevant pages
5. **Content chunking** of relevant pages for detailed analysis
6. **Cosine similarity** calculation for each chunk against the query
7. **LLM processing** to generate structured response with:
   - Concise summary
   - Detailed results with sources
   - Relevance scores
   - Reference links and favicons
   - Confidence ratings

### Response Format
```json
{
  "summary": "Concise overview addressing the query directly",
  "results": [
    {
      "point": "Detailed information in markdown format",
      "reference": "https://exact-source-url.com",
      "reference_favicon": "https://exact-source-url.com/favicon.ico",
      "relevance_score": 0.95,
      "timestamp": "when this info was published/updated"
    }
  ],
  "language": "detected_language_code",
  "last_updated": "timestamp",
  "confidence": 0.90
}
```

### Crawling Process

When you run the spider, you'll be prompted to:
- Enter URLs you want to crawl
- Set the number of workers (default: 5)

The crawler will:
- Extract content from each page
- Generate embeddings in real-time
- Store vectors in Qdrant
- Store metadata in PostgreSQL

### Manual Service Configuration

Since `froxy.sh` only handles the crawler, you'll need to manually configure:

- **Froxy Apex**: Set up your Groq API key and other environment variables
- **Frontend**: Configure API endpoints and keys
- **Service startup**: Start each service individually after crawler completes

---

## ðŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Next.js UI   â”‚â”€â”€â”€â–¶â”‚  Search Backend  â”‚â”€â”€â”€â–¶â”‚   PostgreSQL    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚                       â”‚
         â”‚                       â–¼
         â”‚              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚              â”‚     Qdrant       â”‚â—€â”€â”€â”€â”‚   FastEmbed     â”‚
         â”‚              â”‚ (Vector Search)  â”‚    â”‚   (Embeddings)  â”‚
         â”‚              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚                       â–²                       â–²
         â”‚                       â”‚                       â”‚
         â”‚              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”              â”‚
         â”‚              â”‚   Go Crawler     â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚              â”‚  (Real-time      â”‚
         â”‚              â”‚   Indexing)      â”‚
         â”‚              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Froxy Apex    â”‚â”€â”€â”€â–¶â”‚   Groq LLM API   â”‚    â”‚  Chunk Analysis â”‚
â”‚ (AI Search)     â”‚    â”‚ (Llama 3.1 8B)   â”‚â—€â”€â”€â”€â”‚ (Cosine Sim)    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ðŸ“™ Tech Stack

* ðŸ•·ï¸ **Go (Golang)** â€“ crawler with real-time indexing
* ðŸ§  **FastEmbed** â€“ embedding generation service
* ðŸš€ **Qdrant** â€“ vector database for semantic search
* ðŸ¤– **Froxy Apex** â€“ AI-powered search with LLM integration
* ðŸ¦™ **Llama 3.1 8B** â€“ language model via Groq API
* ðŸ’ª **Node.js** â€“ search backend API
* ðŸ“€ **PostgreSQL** â€“ structured data storage
* âš›ï¸ **Next.js** â€“ frontend interface
* ðŸŽ¨ **TailwindCSS + shadcn/ui** â€“ UI components
* ðŸ³ **Docker** â€“ containerized services
* ðŸŒ **Docker Network** â€“ service communication

---

## ðŸš€ Key Improvements

* **AI-Powered Search**: Perplexity-style intelligent search with LLM integration
* **Semantic Search**: Find content by meaning, not just keywords
* **Real-time Indexing**: Content is indexed as it's crawled
* **Vector Similarity**: Intelligent search results based on context
* **Chunk Analysis**: Deep content analysis with cosine similarity
* **Structured Responses**: Rich JSON responses with sources and confidence scores
* **Query Enhancement**: AI-powered query understanding and improvement
* **Scalable Architecture**: Microservices with Docker containers
* **Automated Setup**: One-command deployment with `froxy.sh`

---

## ðŸ“¬ Want to contribute?

* Fork it ðŸŒ›
* Open a PR ðŸš°
* Share your ideas ðŸ’¡

---

## ðŸ“œ License

**MIT** â€” feel free to fork, remix, and learn from it.

---

Made with â¤ï¸ for the curious minds of the internet.

Stay weird. Stay building.

> "Not all who wander are lost â€” some are just crawling the web with semantic understanding."